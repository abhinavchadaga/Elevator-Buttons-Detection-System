{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# d2 libraries\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.config import get_cfg, LazyConfig, instantiate\n",
    "from detectron2.utils import comm\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.engine.hooks import EvalHook, BestCheckpointer\n",
    "from detectron2.data import (\n",
    "    MetadataCatalog,\n",
    "    DatasetCatalog,\n",
    "    build_detection_train_loader,\n",
    "    build_detection_test_loader,\n",
    "    get_detection_dataset_dicts,\n",
    "    DatasetMapper,\n",
    ")\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# my stuff\n",
    "from data_utils import (\n",
    "    read_split_file,\n",
    "    register_dataset,\n",
    "    random_split_mixed_set,\n",
    "    random_split_ut_west_campus_set\n",
    ")\n",
    "\n",
    "# setup D2 logger\n",
    "setup_logger()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_split_mixed_set(img_dir=\"data/panels/mixed\", split_ratio=(0.7, 0.1, 0.2), seed=10)\n",
    "mixed_datasets = read_split_file(\"data/panels/mixed/split.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_split_ut_west_campus_set(\"data/panels/ut_west_campus\", split_ratio=(0.7, 0.1, 0.2), seed=10)\n",
    "ut_west_campus_datasets = read_split_file(\"data/panels/ut_west_campus/split.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"label\", \"button\"]\n",
    "colors = [(0, 255, 0), (0, 0, 255)]\n",
    "\n",
    "dataset_names = [\n",
    "    \"mixed_train\",\n",
    "    \"mixed_val\",\n",
    "    \"mixed_test\",\n",
    "    \"ut_west_campus_train\",\n",
    "    \"ut_west_campus_val\",\n",
    "    \"ut_west_campus_test\",\n",
    "]\n",
    "\n",
    "# register combined training and validation sets\n",
    "for name, im_paths in zip(dataset_names, mixed_datasets + ut_west_campus_datasets):\n",
    "    DatasetCatalog.register(\n",
    "        name=name, func=lambda im_paths=im_paths: register_dataset(im_paths=im_paths)\n",
    "    )\n",
    "    MetadataCatalog.get(name=name).set(thing_classes=classes, thing_colors=colors)\n",
    "\n",
    "elevator_metadata = MetadataCatalog.get(\"mixed_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_train = DatasetCatalog.get(\"mixed_train\")\n",
    "ut_west_campus_train = DatasetCatalog.get(\"ut_west_campus_train\")\n",
    "trainset = mixed_train + ut_west_campus_train\n",
    "print(\"total trainset len: \", len(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in random.sample(trainset, 5):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    print(d[\"file_name\"])\n",
    "    visualizer = Visualizer(\n",
    "        img[:, :, ::-1],\n",
    "        metadata=elevator_metadata,\n",
    "        scale=1,\n",
    "        instance_mode=ColorMode.SEGMENTATION,\n",
    "    )\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(args, cfg):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        cfg: an object with the following attributes:\n",
    "            model: instantiate to a module\n",
    "            dataloader.{train,test}: instantiate to dataloaders\n",
    "            dataloader.evaluator: instantiate to evaluator for test set\n",
    "            optimizer: instantaite to an optimizer\n",
    "            lr_multiplier: instantiate to a fvcore scheduler\n",
    "            train: other misc config defined in `configs/common/train.py`, including:\n",
    "                output_dir (str)\n",
    "                init_checkpoint (str)\n",
    "                amp.enabled (bool)\n",
    "                max_iter (int)\n",
    "                eval_period, log_period (int)\n",
    "                device (str)\n",
    "                checkpointer (dict)\n",
    "                ddp (dict)\n",
    "    \"\"\"\n",
    "    model = instantiate(cfg.model)\n",
    "    logger = logging.getLogger(\"detectron2\")\n",
    "    logger.info(\"Model:\\n{}\".format(model))\n",
    "    model.to(cfg.train.device)\n",
    "\n",
    "    cfg.optimizer.params.model = model\n",
    "    optim = instantiate(cfg.optimizer)\n",
    "\n",
    "    train_loader = instantiate(cfg.dataloader.train)\n",
    "\n",
    "    model = create_ddp_model(model, **cfg.train.ddp)\n",
    "    trainer = (AMPTrainer if cfg.train.amp.enabled else SimpleTrainer)(model, train_loader, optim)\n",
    "    checkpointer = DetectionCheckpointer(\n",
    "        model,\n",
    "        cfg.train.output_dir,\n",
    "        trainer=trainer,\n",
    "    )\n",
    "    trainer.register_hooks(\n",
    "        [\n",
    "            hooks.IterationTimer(),\n",
    "            hooks.LRScheduler(scheduler=instantiate(cfg.lr_multiplier)),\n",
    "            hooks.PeriodicCheckpointer(checkpointer, **cfg.train.checkpointer)\n",
    "            if comm.is_main_process()\n",
    "            else None,\n",
    "            hooks.EvalHook(cfg.train.eval_period, lambda: do_test(cfg, model)),\n",
    "            hooks.PeriodicWriter(\n",
    "                default_writers(cfg.train.output_dir, cfg.train.max_iter),\n",
    "                period=cfg.train.log_period,\n",
    "            )\n",
    "            if comm.is_main_process()\n",
    "            else None,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    checkpointer.resume_or_load(cfg.train.init_checkpoint, resume=args.resume)\n",
    "    if args.resume and checkpointer.has_checkpoint():\n",
    "        # The checkpoint stores the training iteration that just finished, thus we start\n",
    "        # at the next iteration\n",
    "        start_iter = trainer.iter + 1\n",
    "    else:\n",
    "        start_iter = 0\n",
    "    trainer.train(start_iter, cfg.train.max_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-d2-py",
   "language": "python",
   "name": "conda-env-d2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28c02856d081f5be58732558716d77e5df396d4da9ba084bc37d458bab6a80ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
