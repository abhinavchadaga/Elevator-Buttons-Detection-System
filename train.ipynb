{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfeea4f9-03bc-47ea-a85a-18f8830fbb1f",
   "metadata": {},
   "source": [
    "# Training Notebook\n",
    "\n",
    "Training on Mixed and UT-West-Campus datasets. Evaluate on test portion of both\n",
    "\n",
    "Train Mask-RCNN + ResNet101 Backbone\n",
    "\n",
    "Add a couple additional things: \n",
    "- Validation Loop using loss \n",
    "- Checkpoint based off of best validation metrics\n",
    "- Custom COCO Style Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3add03-615e-4957-94e1-09aab321febd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# d2 libraries\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils import comm\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.engine.hooks import EvalHook, BestCheckpointer\n",
    "from detectron2.data import (\n",
    "    MetadataCatalog,\n",
    "    DatasetCatalog,\n",
    "    build_detection_train_loader,\n",
    "    build_detection_test_loader,\n",
    "    get_detection_dataset_dicts,\n",
    "    DatasetMapper,\n",
    ")\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# my stuff\n",
    "from data_utils import (\n",
    "    read_split_file,\n",
    "    register_dataset,\n",
    "    random_split_mixed_set,\n",
    "    random_split_ut_west_campus_set\n",
    ")\n",
    "\n",
    "# setup D2 logger\n",
    "setup_logger()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156c4d6-ece1-493a-82d3-8088e5028178",
   "metadata": {},
   "source": [
    "### Randomly Split Mixed Dataset\n",
    "\n",
    "For reproducibility we seed the shuffler with the value 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa3ba0-3a4c-4dd7-82d9-1e1e060752ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_split_mixed_set(img_dir=\"data/panels/mixed\", split_ratio=(0.7, 0.1, 0.2), seed=10)\n",
    "mixed_datasets = read_split_file(\"data/panels/mixed/split.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61964f9-2ec1-4b03-ae1b-914f47cf252c",
   "metadata": {},
   "source": [
    "### Randomly Split UT-West-Campus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e6d6c-a5bb-456f-8c9e-54e0e3f4fb82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_split_ut_west_campus_set(\"data/panels/ut_west_campus\", split_ratio=(0.7, 0.1, 0.2), seed=10)\n",
    "ut_west_campus_datasets = read_split_file(\"data/panels/ut_west_campus/split.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd66235-3ce5-4178-bb32-d9b6f4df8439",
   "metadata": {},
   "source": [
    "### Register Mixed Dataset Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98157095-10f9-42bd-b392-895fe59a3dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [\"label\", \"button\"]\n",
    "colors = [(0, 255, 0), (0, 0, 255)]\n",
    "\n",
    "dataset_names = [\n",
    "    \"mixed_train\",\n",
    "    \"mixed_val\",\n",
    "    \"mixed_test\",\n",
    "    \"ut_west_campus_train\",\n",
    "    \"ut_west_campus_val\",\n",
    "    \"ut_west_campus_test\",\n",
    "]\n",
    "\n",
    "# register combined training and validation sets\n",
    "for name, im_paths in zip(dataset_names, mixed_datasets + ut_west_campus_datasets):\n",
    "    DatasetCatalog.register(\n",
    "        name=name, func=lambda im_paths=im_paths: register_dataset(im_paths=im_paths)\n",
    "    )\n",
    "    MetadataCatalog.get(name=name).set(thing_classes=classes, thing_colors=colors)\n",
    "\n",
    "elevator_metadata = MetadataCatalog.get(\"mixed_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53aca5b-fa58-41f7-8825-b59889d0536f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mixed_train = DatasetCatalog.get(\"mixed_train\")\n",
    "ut_west_campus_train = DatasetCatalog.get(\"ut_west_campus_train\")\n",
    "trainset = mixed_train + ut_west_campus_train\n",
    "print(\"total trainset len: \", len(trainset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2247a5-5102-4402-a9b6-c4d43293f7d8",
   "metadata": {},
   "source": [
    "### Visualize Training Data Samples\n",
    "\n",
    "Ensure that data is annotated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cee54c-08e5-4b00-a38b-cba8a4dcde8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for d in random.sample(trainset, 5):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    print(d[\"file_name\"])\n",
    "    visualizer = Visualizer(\n",
    "        img[:, :, ::-1],\n",
    "        metadata=elevator_metadata,\n",
    "        scale=1,\n",
    "        instance_mode=ColorMode.SEGMENTATION,\n",
    "    )\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6c7a89-144d-484a-bb9c-b85deace5223",
   "metadata": {},
   "source": [
    "### Validation Loop using Validation Loss\n",
    "\n",
    "as opposed to evaluation metrics (AP, Precision, Recall, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de170095-7db7-4adf-aa4f-1efae35f1490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_loop(model: torch.nn, dataloader: torch.utils.data.DataLoader) -> dict:\n",
    "    \"\"\"\n",
    "    Validate model on the given dataloader. Put model in training mode to output loss\n",
    "    dict but do not backpropogate gradients. Largely adapted from train_loop.py and\n",
    "    inference_on_dataset\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn): model to validate\n",
    "        dataloader (torch.utils.data.DataLoader): validation dataloader set to training\n",
    "            mode\n",
    "\n",
    "    Returns:\n",
    "        dict: {\"validation_loss\": val_loss}\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    num_warmup = min(5, num_batches - 1)\n",
    "    start_time = time.perf_counter()\n",
    "    total_compute_time = 0\n",
    "    losses = []\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        if idx == num_warmup:\n",
    "            start_time = time.perf_counter()\n",
    "            total_compute_time = 0\n",
    "        start_compute_time = time.perf_counter()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        total_compute_time += time.perf_counter() - start_compute_time\n",
    "        iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "        seconds_per_img = total_compute_time / iters_after_start\n",
    "        if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "            total_seconds_per_img = (\n",
    "                time.perf_counter() - start_time\n",
    "            ) / iters_after_start\n",
    "            eta = datetime.timedelta(\n",
    "                seconds=int(total_seconds_per_img) * (num_batches - idx - 1)\n",
    "            )\n",
    "            log_every_n_seconds(\n",
    "                logging.INFO,\n",
    "                \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                    idx + 1, num_batches, seconds_per_img, str(eta)\n",
    "                ),\n",
    "                n=5,\n",
    "            )\n",
    "\n",
    "        batch_loss_dict = model(data)\n",
    "        batch_loss_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in batch_loss_dict.items()\n",
    "        }\n",
    "        total_batch_loss = sum(loss for loss in batch_loss_dict.values())\n",
    "        losses.append(total_batch_loss)\n",
    "    val_loss = np.mean(losses)\n",
    "    comm.synchronize()\n",
    "    log_every_n_seconds(logging.INFO, f\"VALIDATION_LOSS: {val_loss:.5f}\")\n",
    "    return {\"validation_loss\": val_loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf678953-cab0-4b60-b347-7739ad3fa63b",
   "metadata": {},
   "source": [
    "### Define a Custom Trainer\n",
    "\n",
    "Add custom hooks and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7159857-76cf-42af-91ba-3a3caca5615a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(\n",
    "            dataset=get_detection_dataset_dicts(\n",
    "                cfg.DATASETS.TRAIN[0], filter_empty=False\n",
    "            ),\n",
    "            mapper=DatasetMapper(\n",
    "                is_train=True,\n",
    "                augmentations=[\n",
    "                    T.ResizeScale(\n",
    "                        min_scale=0.1,\n",
    "                        max_scale=2.0,\n",
    "                        target_height=1024,\n",
    "                        target_width=1024,\n",
    "                    ),\n",
    "                    T.FixedSizeCrop(crop_size=(1024, 1024), pad=False),\n",
    "                ],\n",
    "                image_format=\"RGB\",\n",
    "                use_instance_mask=True,\n",
    "                recompute_boxes=True,\n",
    "            ),\n",
    "            total_batch_size=cfg.SOLVER.IMS_PER_BATCH,\n",
    "            num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def build_validation_loader(cls, cfg):\n",
    "        return build_detection_test_loader(\n",
    "            dataset=get_detection_dataset_dicts(\n",
    "                cfg.DATASETS.VAL[0], filter_empty=False\n",
    "            ),\n",
    "            mapper=DatasetMapper(\n",
    "                is_train=True,\n",
    "                augmentations=[\n",
    "                    T.ResizeShortestEdge(short_edge_length=1024, max_size=1024)\n",
    "                ],\n",
    "                image_format=\"BGR\",\n",
    "                use_instance_mask=True,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def build_hooks(self) -> list:\n",
    "        \"\"\"\n",
    "        Overwrite the evaluation loop and checkpoint using best validation loss\n",
    "\n",
    "        Returns:\n",
    "            list: list of hooks\n",
    "        \"\"\"\n",
    "        hooks = super().build_hooks()\n",
    "        # remove existing EvalHook\n",
    "        if comm.is_main_process():\n",
    "            del hooks[-2]\n",
    "            del hooks[-2]\n",
    "        else:\n",
    "            del hooks[-1]\n",
    "        hooks.extend(\n",
    "            [\n",
    "                EvalHook(\n",
    "                    eval_period=self.cfg.TEST.EVAL_PERIOD,\n",
    "                    eval_function=lambda: validation_loop(\n",
    "                        self.model,\n",
    "                        self.build_validation_loader(self.cfg),\n",
    "                    ),\n",
    "                    eval_after_train=True,\n",
    "                ),\n",
    "                BestCheckpointer(\n",
    "                    eval_period=self.cfg.TEST.EVAL_PERIOD,\n",
    "                    checkpointer=self.checkpointer,\n",
    "                    val_metric=\"validation_loss\",\n",
    "                    mode=\"min\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        return hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7243c3-044e-4f97-a539-8af4e13b8f32",
   "metadata": {},
   "source": [
    "### Define Config for Building Model\n",
    "\n",
    "Use Mask-RCNN w/ ResNet-101 Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d785ae-e19c-46cc-a140-fa6fbc836beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_rcnn_res50 = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "mask_rcnn_res101 = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
    "cascade_mask_rcnn_res50 = \"Misc/cascade_mask_rcnn_R_50_FPN_3x.yaml\"\n",
    "\n",
    "base_cfg = mask_rcnn_res101\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(base_cfg))\n",
    "\n",
    "# start from pretrained weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(base_cfg)\n",
    "\n",
    "# assign datasets and adjust ROI HEADS to match num classes\n",
    "cfg.DATASETS.TRAIN = (\"mixed_train\", \"ut_west_campus_train\")\n",
    "cfg.DATASETS.VAL = (\"mixed_val\", \"ut_west_campus_val\")\n",
    "cfg.DATASETS.TEST = (\"mixed_test\", \"ut_west_campus_test\")\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.INPUT.RANDOM_FLIP = \"none\"\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "\n",
    "# Calculate training logic\n",
    "epochs = 100\n",
    "batch_size = 2\n",
    "eval_period = 2\n",
    "iters_per_epoch = math.ceil(len(trainset) / batch_size)\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "cfg.SOLVER.MAX_ITER = iters_per_epoch * epochs\n",
    "cfg.TEST.EVAL_PERIOD = iters_per_epoch * eval_period\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.STEPS = [int(0.7 * cfg.SOLVER.MAX_ITER), int(0.8 * cfg.SOLVER.MAX_ITER)]\n",
    "cfg.SOLVER.WARMUP_ITERS = int(0.067 * cfg.SOLVER.MAX_ITER)\n",
    "\n",
    "# SAVE DIR\n",
    "cfg.OUTPUT_DIR = \"./models/combined_v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b7ea7-d31f-45bb-aa1a-32babd13fb21",
   "metadata": {},
   "source": [
    "### Train Configured Model\n",
    "\n",
    "Use modified DefaultTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959b240-42ce-4978-8d0d-4076f082a331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6734299-f598-45ee-b566-bcf7b9af14c3",
   "metadata": {},
   "source": [
    "### Plot Training and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc904eee-26ab-4e72-b260-74fab4ff0906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_json_arr(json_path):\n",
    "    train, val = [], []\n",
    "    with open(json_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line)\n",
    "            if \"validation_loss\" in line:\n",
    "                val.append(line)\n",
    "            elif \"total_loss\" in line:\n",
    "                train.append(line)\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4726f-51ab-471a-b984-ecc01ce8505e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_metrics, val_metrics = load_json_arr(os.path.join(cfg.OUTPUT_DIR, \"metrics.json\"))\n",
    "train_metrics = train_metrics[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492cbce-cdbb-4a7d-b631-fb8202ec11fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_iters = [x[\"iteration\"] for x in train_metrics]\n",
    "train_loss = [x[\"total_loss\"] for x in train_metrics]\n",
    "\n",
    "val_iters = [x[\"iteration\"] for x in val_metrics]\n",
    "val_loss = [x[\"validation_loss\"] for x in val_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d406e-81b7-488d-a4d4-368102844cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train_iters, train_loss)\n",
    "plt.plot(val_iters, val_loss)\n",
    "plt.xlabel(\"iters\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"train/val loss\")\n",
    "plt.legend([\"training loss\", \"validation loss\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf7e992e-6afd-4656-99be-d419a35561f3",
   "metadata": {},
   "source": [
    "### Evalatuate Model on Mixed Testset\n",
    "\n",
    "Using Default Predictor with Threshold of 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca041d4-8e21-4bbd-8687-91c2c29ab425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_best.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ebcaa7-5064-404f-b040-636b9af703c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = COCOEvaluator(\n",
    "    dataset_name=\"mixed_test\",\n",
    "    output_dir=os.path.join(cfg.OUTPUT_DIR, \"inference\", \"mixed\"),\n",
    "    allow_cached_coco=False,\n",
    "    use_fast_impl=False,\n",
    ")\n",
    "testloader = build_detection_test_loader(cfg, \"mixed_test\")\n",
    "print(inference_on_dataset(predictor.model, testloader, evaluator))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c422ecd7-bd62-4607-8baa-714d07634d02",
   "metadata": {},
   "source": [
    "### Visualize Inference on Mixed Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2426f-5064-45a9-862e-1e5122d3c499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_inference(dataset_name: str, k: int):\n",
    "    testset = get_detection_dataset_dicts(dataset_name, filter_empty=False)\n",
    "    for d in random.sample(testset, k):\n",
    "        img = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(img)\n",
    "        v = Visualizer(\n",
    "            img[:, :, ::-1],\n",
    "            metadata=MetadataCatalog.get(dataset_name),\n",
    "            scale=1.0,\n",
    "            instance_mode=ColorMode.SEGMENTATION,\n",
    "        )\n",
    "        out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        plt.imshow(out.get_image())\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35720982-6379-4ff0-9db6-a8446aaa5e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_inference(\"mixed_test\", 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80d498a3-080a-4ea2-a3be-d0ccd5a6896a",
   "metadata": {},
   "source": [
    "### Evaluate Model on UT-West-Campus Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb4cf6-4253-4c59-ad04-c53c84d61f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator = COCOEvaluator(\n",
    "    dataset_name=\"ut_west_campus_test\",\n",
    "    output_dir=os.path.join(cfg.OUTPUT_DIR, \"inference\", \"ut_west_campus\"),\n",
    "    allow_cached_coco=False,\n",
    "    use_fast_impl=False,\n",
    ")\n",
    "testloader = build_detection_test_loader(cfg, \"ut_west_campus_test\")\n",
    "print(inference_on_dataset(predictor.model, testloader, evaluator))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ffbf752-1d17-4a4d-8fc4-90ec0c8a63f0",
   "metadata": {},
   "source": [
    "### Visualize Inference on UT-West-Campus Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be210b-e7bc-4d77-9e0d-ec55ea49f3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_inference(\"ut_west_campus_test\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-d2-py",
   "language": "python",
   "name": "conda-env-d2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "28c02856d081f5be58732558716d77e5df396d4da9ba084bc37d458bab6a80ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
